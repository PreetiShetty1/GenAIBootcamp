{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": { "provenance": [] },
    "kernelspec": { "name": "python3", "display_name": "Python 3" },
    "language_info": { "name": "python" }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Learn Prompt Engineering ‚Äî Intern Exercise Workbook**\n",
        "\n",
        "This workbook covers core prompt engineering techniques: summarization, question answering, classification, information extraction, translation, tone transformation, role playing, code generation, reasoning, few-shot prompting, and chain-of-thought (CoT).\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Instructions\n",
        "- Each section has **questions** with `# TODO` or `___` blanks.\n",
        "- **Fill in the blanks** and **run each cell** to verify.\n",
        "- üéØ = Hint | üèÜ = Bonus Challenge\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup\n",
        "\n",
        "We need to install libraries and create a helper function to talk to the LLM."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.1 ‚Äî Install Required Libraries\n",
        "\n",
        "**Task:** Install `openai` (version 0.28) and `rich` (for pretty printing)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Install openai==0.28 and rich\n",
        "\n",
        "!pip install ___\n",
        "!pip install ___"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.2 ‚Äî Create the OpenAI Client\n",
        "\n",
        "**Task:** Set up the OpenAI client using the newer `openai.OpenAI()` approach.\n",
        "\n",
        "üéØ **Hint:** The client is created with `openai.OpenAI(api_key=\"...\")`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from rich import print\n",
        "\n",
        "# TODO: Create the OpenAI client with your API key\n",
        "client = openai.OpenAI(\n",
        "    api_key= \"___\"  # Replace with your actual API key\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.3 ‚Äî Understand the Chat API Structure\n",
        "\n",
        "The Chat API uses **messages** with different **roles**:\n",
        "- `system` ‚Äî Sets the AI's behavior/persona\n",
        "- `user` ‚Äî The human's message\n",
        "- `assistant` ‚Äî The AI's previous response (for multi-turn)\n",
        "\n",
        "**Task:** Fill in the missing roles and content in the API call below. The conversation should:\n",
        "1. Set a **system** message: \"You are an AI research assistant. You use a tone that is technical and scientific.\"\n",
        "2. Have a **user** greeting: \"Hello, who are you?\"\n",
        "3. Have an **assistant** reply: \"Greeting! I am an AI research assistant. How can I help you today?\"\n",
        "4. Have a **user** follow-up: \"Can you tell me about the creation of black holes?\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-3.5-turbo\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=MODEL,\n",
        "    messages=[\n",
        "        {\"role\": \"___\", \"content\": \"___\"},  # System persona\n",
        "        {\"role\": \"___\", \"content\": \"___\"},  # User greeting\n",
        "        {\"role\": \"___\", \"content\": \"___\"},  # Assistant reply\n",
        "        {\"role\": \"___\", \"content\": \"___\"}   # User follow-up question\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# TODO: Print only the text content from the response\n",
        "# üéØ Hint: response.choices[0].message.content\n",
        "print(___)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.4 ‚Äî Build a Reusable Helper Function\n",
        "\n",
        "**Task:** Complete the `get_completion` function that:\n",
        "- Accepts `messages` (list of dicts), `model`, `temperature`, and `max_tokens`\n",
        "- Calls the Chat Completions API\n",
        "- Returns **only the text content**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=4000):\n",
        "    \"\"\"Send messages to the Chat API and return the response text.\"\"\"\n",
        "\n",
        "    # TODO: Call client.chat.completions.create() with the 4 parameters\n",
        "    response = client.chat.completions.create(\n",
        "        model=___,\n",
        "        messages=___,\n",
        "        temperature=___,\n",
        "        max_tokens=___,\n",
        "    )\n",
        "\n",
        "    # TODO: Return the text content\n",
        "    return ___"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 2: Basic Prompt & Text Completion\n",
        "\n",
        "The simplest form of prompting ‚Äî give the model a partial sentence and let it complete."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.1 ‚Äî Text Completion\n",
        "\n",
        "**Task:** Send the prompt `\"The sky is\"` to the model and print the completion. Wrap it in the correct message format."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"The sky is\"\n",
        "\n",
        "# TODO: Create the message list with the correct role and content\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"___\",\n",
        "        \"content\": ___\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 3: Text Summarization\n",
        "\n",
        "Summarization condenses long text into short, digestible content. We'll see how **iterative refinement** improves results."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.1 ‚Äî Basic Summarization (Append Instruction)\n",
        "\n",
        "**Task:** Given the paragraph about antibiotics below, add an instruction at the end to summarize it in one sentence.\n",
        "\n",
        "üéØ **Hint:** Simply append `\"Explain the above in one sentence:\"` after the text."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the prompt ‚Äî add the text and the summarization instruction\n",
        "\n",
        "prompt = \"\"\"Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\n",
        "___\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message, temperature=0)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.2 ‚Äî Better Summarization (Task-First Approach)\n",
        "\n",
        "A better pattern: **state the task FIRST**, then provide the data.\n",
        "\n",
        "**Task:** Rewrite the prompt so the instruction comes before the abstract. Use the label `Abstract:` to separate them."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the prompt with instruction FIRST, then the abstract\n",
        "\n",
        "prompt = \"\"\"\n",
        "___  # Instruction: what should the model do?\n",
        "\n",
        "Abstract: Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message, temperature=0)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.3 ‚Äî Iterative Refinement (Adding Constraints)\n",
        "\n",
        "**Task:** Further improve the prompt by adding a **constraint**: `\"Avoid technical jargon and explain it in the simplest of words.\"`\n",
        "\n",
        "üèÜ **Compare:** How does the output differ from Q3.2?"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add the simplification constraint to the prompt\n",
        "\n",
        "prompt = \"\"\"\n",
        "Your task is to summarize an abstract into one sentence.\n",
        "\n",
        "___  # Add the simplification constraint here\n",
        "\n",
        "Abstract: Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
        "\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message, temperature=0)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 4: Question Answering\n",
        "\n",
        "LLMs can answer questions based on a provided **context**. The key is to clearly separate the context, question, and expected behavior."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4.1 ‚Äî Context-Based QA\n",
        "\n",
        "**Task:** Complete the prompt below to:\n",
        "1. Instruct the model to answer based **only** on the context\n",
        "2. Keep the answer short and concise\n",
        "3. Respond `\"Unsure about answer\"` if not confident\n",
        "4. Ask: \"What was OKT3 originally sourced from?\""
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the instruction, fallback behavior, and question\n",
        "\n",
        "prompt = \"\"\"___  # Instruction: answer based on context, keep short, respond \"Unsure\" if not sure\n",
        "\n",
        "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
        "\n",
        "Question: ___\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 5: Text Classification\n",
        "\n",
        "LLMs can classify text into categories ‚Äî sentiment analysis, topic classification, etc."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5.1 ‚Äî Sentiment Classification\n",
        "\n",
        "**Task:** Complete the prompt to classify user input into `neutral`, `negative`, or `positive`. Use triple backticks ` ``` ` as delimiters around the input text.\n",
        "\n",
        "üéØ **Hint:** Use `{user_input}` inside the backticks and `.format()` to inject the value."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"I think the food was okay\"\n",
        "\n",
        "# TODO: Write the classification prompt with delimited input\n",
        "prompt = \"\"\"___  # Instruction: classify into neutral/negative/positive\n",
        "\n",
        "Text: ```{user_input}```\n",
        "\n",
        "Sentiment:\"\"\"\n",
        "\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt.format(user_input=___)\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 6: Information Extraction\n",
        "\n",
        "Extract structured information (names, entities, tags) from unstructured text."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6.1 ‚Äî Extract Model Names from a Paper Abstract\n",
        "\n",
        "**Task:** Write a prompt that extracts AI/ML model names from a paper abstract and returns them as a JSON array `[\"model_name\"]`. If no models found, return `[\"NA\"]`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the extraction prompt\n",
        "\n",
        "prompt = \"\"\"___  # Instruction: what to extract, what format, what to return if not found\n",
        "\n",
        "Abstract: Large Language Models (LLMs), such as ChatGPT and GPT-4, have revolutionized natural language processing research and demonstrated potential in Artificial General Intelligence (AGI). However, the expensive training and deployment of LLMs present challenges to transparent and open academic research. To address these issues, this project open-sources the Chinese LLaMA and Alpaca...\n",
        "\n",
        "Tags:\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 7: Translation & Tone Transformation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7.1 ‚Äî Machine Translation\n",
        "\n",
        "**Task:** Write a prompt to translate `\"Glad to be here!\"` from English to Spanish."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the translation prompt\n",
        "\n",
        "prompt = \"\"\"___\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7.2 ‚Äî Tone Transformation\n",
        "\n",
        "LLMs can transform the **emotional tone** of text ‚Äî not just the language.\n",
        "\n",
        "**Task:** Write a prompt to transform `\"Glad to be here!\"` from a **happy** tone to a **super excited** tone."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the tone transformation prompt\n",
        "\n",
        "prompt = \"\"\"___\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 8: Role Playing\n",
        "\n",
        "The model can take on different **personas** using the `system` message or by describing the role in the prompt."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8.1 ‚Äî Role Playing (Single Prompt)\n",
        "\n",
        "**Task:** Write a single prompt that includes a conversation between a Human and an AI research assistant. The AI should have a technical/scientific tone. End with the human asking about black holes."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the role-playing prompt as a single text block\n",
        "\n",
        "prompt = \"\"\"___  # Describe the AI's persona and tone\n",
        "\n",
        "Human: Hello, who are you?\n",
        "AI: Greeting! I am an AI research assistant. How can I help you today?\n",
        "Human: ___\n",
        "AI:\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8.2 ‚Äî Role Playing (System Message Approach)\n",
        "\n",
        "**Task:** Achieve the **same result** as Q8.1 but using the proper `system` / `user` / `assistant` message structure. This is the **recommended** approach.\n",
        "\n",
        "Fill in the roles and content for each message in the conversation."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Build the conversation using separate system/user/assistant messages\n",
        "\n",
        "system_message = \"\"\"___\"\"\"  # Persona description\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"___\", \"content\": system_message},             # System\n",
        "    {\"role\": \"___\", \"content\": \"___\"},                      # User greeting\n",
        "    {\"role\": \"___\", \"content\": \"___\"},                      # Assistant reply\n",
        "    {\"role\": \"___\", \"content\": \"___\"},                      # User question about black holes\n",
        "]\n",
        "\n",
        "response = get_completion(messages)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 9: Code Generation\n",
        "\n",
        "LLMs can generate code from natural language descriptions of database schemas and requirements."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q9.1 ‚Äî Generate SQL from Schema Description\n",
        "\n",
        "**Task:** Write a prompt that provides:\n",
        "- Table `departments` with columns `[DepartmentId, DepartmentName]`\n",
        "- Table `students` with columns `[DepartmentId, StudentId, StudentName]`\n",
        "- Request: Create a MySQL query for all students in the Computer Science Department"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the code generation prompt with schema + request\n",
        "\n",
        "prompt = \"\"\"___\"\"\"\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 10: Reasoning\n",
        "\n",
        "LLMs can solve logical/math problems ‚Äî but they do **much better** when asked to break problems into steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q10.1 ‚Äî Step-by-Step Reasoning\n",
        "\n",
        "**Task:** Write a prompt that asks whether the odd numbers in `[15, 32, 5, 13, 82, 7, 1]` add up to an even number. **Crucially**, instruct the model to solve step-by-step: first identify odd numbers, then add them, then check if the result is odd or even."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the reasoning prompt with step-by-step instructions\n",
        "\n",
        "prompt = \"\"\"___  # State the problem\n",
        "\n",
        "___\"\"\"  # Instruction to break it into steps\n",
        "\n",
        "message = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(message)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 11: Advanced ‚Äî Few-Shot Prompting\n",
        "\n",
        "**Few-shot prompting** provides the model with **examples** of input-output pairs before asking it to solve a new problem. This teaches the model the expected format and reasoning pattern."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q11.1 ‚Äî Few-Shot Odd Number Problem\n",
        "\n",
        "**Task:** Provide 4 examples of the odd-number-sum problem with answers (True/False), then ask the model to solve a 5th one.\n",
        "\n",
        "üéØ **Hint:** The pattern is:\n",
        "```\n",
        "The odd numbers in this group add up to an even number: [numbers]\n",
        "A: The answer is True/False.\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write a few-shot prompt with 4 examples + 1 question\n",
        "\n",
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: ___\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
        "A: ___\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
        "A: ___\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
        "A: ___\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(messages)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 12: Advanced ‚Äî Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "**Chain-of-Thought** prompting shows the model HOW to reason through a problem, not just the answer. The example includes intermediate reasoning steps."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q12.1 ‚Äî Without CoT (Baseline)\n",
        "\n",
        "**Task:** Ask the model directly if the odd numbers in `[15, 32, 5, 13, 82, 7, 1]` add up to an even number. Just ask for True/False ‚Äî **no reasoning steps**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write a direct (no-CoT) prompt\n",
        "\n",
        "prompt = \"\"\"___\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(messages)\n",
        "print(\"Without CoT:\", response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q12.2 ‚Äî With CoT (One Example with Reasoning)\n",
        "\n",
        "**Task:** Now provide ONE example that includes the **reasoning steps** (identify odd numbers ‚Üí add them ‚Üí state result), then ask the model to solve the second problem the same way.\n",
        "\n",
        "üéØ **Example pattern:**\n",
        "```\n",
        "The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write a CoT prompt with one worked example\n",
        "\n",
        "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: ___  # Show the reasoning: which are odd, what's the sum, is it even?\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(messages)\n",
        "print(\"With CoT:\", response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q12.3 ‚Äî Zero-Shot CoT (Magic Phrase)\n",
        "\n",
        "You can trigger chain-of-thought reasoning **without any examples** by appending a magic phrase!\n",
        "\n",
        "**Task:** Write a word problem and append `\"Let's think step by step.\"` at the end.\n",
        "\n",
        "Problem: *\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\"*"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write the problem and append the zero-shot CoT trigger phrase\n",
        "\n",
        "prompt = \"\"\"___  # The word problem\n",
        "\n",
        "___\"\"\"  # The magic phrase that triggers step-by-step reasoning\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "response = get_completion(messages)\n",
        "print(response)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìù Self-Assessment Checklist\n",
        "\n",
        "| # | Technique | Key Concept | Done? |\n",
        "|---|-----------|------------|-------|\n",
        "| 1 | Setup | `system`/`user`/`assistant` roles, `get_completion()` helper | ‚òê |\n",
        "| 2 | Basic Completion | Partial sentence ‚Üí model completes it | ‚òê |\n",
        "| 3 | Summarization | Task-first, add constraints iteratively | ‚òê |\n",
        "| 4 | Question Answering | Context + Question + fallback instruction | ‚òê |\n",
        "| 5 | Text Classification | Delimit input with backticks, specify categories | ‚òê |\n",
        "| 6 | Information Extraction | Specify output format (JSON array) | ‚òê |\n",
        "| 7 | Translation & Tone | Language translation + emotional tone change | ‚òê |\n",
        "| 8 | Role Playing | Single-prompt vs system-message approach | ‚òê |\n",
        "| 9 | Code Generation | Schema description ‚Üí SQL query | ‚òê |\n",
        "| 10 | Reasoning | Step-by-step instructions improve accuracy | ‚òê |\n",
        "| 11 | Few-Shot | Provide examples to teach the pattern | ‚òê |\n",
        "| 12 | Chain-of-Thought | Show reasoning steps; \"Let's think step by step\" | ‚òê |"
      ],
      "metadata": {}
    }
  ]
}