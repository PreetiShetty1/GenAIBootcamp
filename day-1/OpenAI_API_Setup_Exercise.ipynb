{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": { "provenance": [] },
    "kernelspec": { "name": "python3", "display_name": "Python 3" },
    "language_info": { "name": "python" }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **OpenAI API Setup ‚Äî Intern Exercise Workbook**\n",
        "\n",
        "Learn how to set up the OpenAI API, make your first API call, build a multi-turn chatbot, and experiment with model hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "### üìã Instructions\n",
        "- Fill in all `___` blanks and `# TODO` sections.\n",
        "- Run each cell after completing it to verify your answers.\n",
        "- üéØ = Hint | üèÜ = Bonus Challenge\n",
        "\n",
        "---"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Install the OpenAI Python Library"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1.1 ‚Äî Install OpenAI\n",
        "\n",
        "**Task:** Install the `openai` package using pip."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Install the openai package\n",
        "\n",
        "!pip install ___"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 2: Set Up Your API Key"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.1 ‚Äî Create the OpenAI Client\n",
        "\n",
        "**Task:** Import the `OpenAI` class and create a client instance with your API key.\n",
        "\n",
        "üéØ **Hint:** The import is `from openai import OpenAI` and the client is created with `OpenAI(api_key=\"...\")`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Import OpenAI and create the client\n",
        "\n",
        "from ___ import ___\n",
        "\n",
        "client = ___(\n",
        "    api_key=\"___\"  # Ask your instructor for the API key\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 3: Making Your First API Call"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.1 ‚Äî Build the `ask_gpt` Function\n",
        "\n",
        "**Task:** Complete the function that:\n",
        "1. Calls `client.chat.completions.create()`\n",
        "2. Uses a **system message** to set the AI's persona as \"a helpful assistant\"\n",
        "3. Passes the user's query as a **user message**\n",
        "4. Prints the assistant's response text\n",
        "\n",
        "üéØ **Hint:** The messages list needs two dicts ‚Äî one with `role: \"system\"` and one with `role: \"user\"`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_gpt(query):\n",
        "    model_choice = \"gpt-4\"\n",
        "\n",
        "    # TODO: Call the Chat Completions API with system + user messages\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_choice,\n",
        "        messages=[\n",
        "            {\"role\": \"___\", \"content\": \"___\"},   # System persona\n",
        "            {\"role\": \"___\", \"content\": ___}       # User query\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # TODO: Print the assistant's response text\n",
        "    # üéØ Hint: response.choices[0].message.content\n",
        "    print('\\nAssistant: ', ___)\n",
        "\n",
        "# Test it!\n",
        "query = input('User: ')\n",
        "ask_gpt(query)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 4: Understanding System Prompts\n",
        "\n",
        "A **system prompt** is a fixed prompt providing context and instructions to the model. It is always included regardless of the user prompt, and should only be edited by developers (not end users).\n",
        "\n",
        "Developers use system prompts to constrain the LLM's answers:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4.1 ‚Äî Identify System Prompt Use Cases\n",
        "\n",
        "**Task:** For each scenario below, write what the system prompt should say. No code needed ‚Äî just write your answers as comments.\n",
        "\n",
        "| Scenario | System Prompt Should... |\n",
        "|----------|------------------------|\n",
        "| A retail chatbot for an online store | Constrain answers to a specific **realm** |\n",
        "| A code review assistant | Define a specific **task** to fulfill |\n",
        "| A travel guide for South Africa | Provide a specific **context** to consider |\n",
        "| A pirate-themed fun assistant | Set a specific **style** for responses |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write system prompts for each scenario\n",
        "\n",
        "# Scenario 1 ‚Äî Retail chatbot:\n",
        "system_retail = \"___\"\n",
        "\n",
        "# Scenario 2 ‚Äî Code review assistant:\n",
        "system_code_review = \"___\"\n",
        "\n",
        "# Scenario 3 ‚Äî South Africa travel guide:\n",
        "system_travel = \"___\"\n",
        "\n",
        "# Scenario 4 ‚Äî Pirate-themed assistant:\n",
        "system_pirate = \"___\"\n",
        "\n",
        "print(\"System prompts written! ‚úÖ\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 5: Adding Conversation History\n",
        "\n",
        "To make the chatbot **remember** previous messages, we maintain a `conversation_history` list and append every user message and assistant response to it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5.1 ‚Äî Build a Multi-Turn Chatbot\n",
        "\n",
        "**Task:** Complete the `prompt_gpt()` function that:\n",
        "1. Starts with a conversation history containing only the system message\n",
        "2. In a loop: takes user input, appends it to history, calls the API with **full history**, appends the response, and prints it\n",
        "3. Exits when the user types `\"exit\"`\n",
        "\n",
        "üéØ **Key insight:** Each API call receives the **entire** conversation history, so the model can reference earlier messages."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the multi-turn chatbot\n",
        "\n",
        "conversation_history = [\n",
        "    {\"role\": \"___\", \"content\": \"___\"}  # System message\n",
        "]\n",
        "\n",
        "def prompt_gpt():\n",
        "    while True:\n",
        "        query = input(\"User: \")\n",
        "\n",
        "        # Exit condition\n",
        "        if query.lower() == 'exit':\n",
        "            print(\"Ending conversation.\")\n",
        "            break\n",
        "\n",
        "        model_choice = \"gpt-3.5-turbo-16k\"\n",
        "\n",
        "        # TODO: Append the user's message to conversation_history\n",
        "        conversation_history.append({\"role\": \"___\", \"content\": ___})\n",
        "\n",
        "        # TODO: Call the API with the full conversation_history\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_choice,\n",
        "            messages=___  # What should go here?\n",
        "        )\n",
        "\n",
        "        # TODO: Extract the assistant's response text\n",
        "        assistant_response = ___\n",
        "\n",
        "        # TODO: Append the assistant's response to conversation_history\n",
        "        conversation_history.append({\"role\": \"___\", \"content\": ___})\n",
        "\n",
        "        print(f\"\\nAssistant: {assistant_response} \\n\")\n",
        "\n",
        "# Run the chatbot! Try: \"hey my name is Krishna\" then \"what is my name?\" then \"exit\"\n",
        "prompt_gpt()"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Section 6: Model Hyperparameters\n",
        "\n",
        "The OpenAI API has several parameters that control the model's behavior:\n",
        "\n",
        "| Parameter | What it does | Range |\n",
        "|-----------|-------------|-------|\n",
        "| `temperature` | Controls randomness (higher = more diverse) | 0 to 2 |\n",
        "| `max_tokens` | Limits response length | 1 to model limit |\n",
        "| `top_p` | Nucleus sampling (limits cumulative probability of tokens) | 0 to 1 |\n",
        "| `n` | Number of alternative completions to generate | 1 to 5+ |\n",
        "| `stop` | String(s) that cause the model to stop generating | string or list |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6.1 ‚Äî Experiment with Hyperparameters\n",
        "\n",
        "**Task:** Complete the `params()` function that demonstrates all 5 hyperparameters. Fill in:\n",
        "1. The API call with all hyperparameters passed in\n",
        "2. The logic to handle multiple completions when `n > 1`\n",
        "\n",
        "üéØ **Experiment:** After filling in the blanks, try changing the values to see how they affect the output!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "def params(query):\n",
        "    model_choice = \"gpt-3.5-turbo-16k\"\n",
        "\n",
        "    # Hyperparameters ‚Äî try changing these!\n",
        "    temperature = 1       # 0 = deterministic, 2 = very random\n",
        "    max_tokens = 5        # Limit output to just 5 tokens\n",
        "    top_p = 0.5           # Only consider top 50% probability tokens\n",
        "    n = 4                 # Generate 4 different completions\n",
        "    stop = (\"Sincerely\", \"Best regards\")  # Stop if these phrases appear\n",
        "\n",
        "    # TODO: Call the API with ALL hyperparameters\n",
        "    response = client.chat.completions.create(\n",
        "        model=model_choice,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": query}\n",
        "        ],\n",
        "        temperature=___,\n",
        "        max_tokens=___,\n",
        "        top_p=___,\n",
        "        n=___,\n",
        "        stop=___\n",
        "    )\n",
        "\n",
        "    # TODO: Print results ‚Äî if n > 1, loop through all choices\n",
        "    if n > 1:\n",
        "        for choice in ___:\n",
        "            print(f\"Output: {___}\\n\")\n",
        "    else:\n",
        "        print(f\"Output: {___}\")\n",
        "\n",
        "\n",
        "# Test with this query\n",
        "query = \"Please write a very polite and a concise email to my boss requesting a raise.\"\n",
        "params(query)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6.2 ‚Äî üèÜ Hyperparameter Prediction\n",
        "\n",
        "**Task:** Without running code, predict the output behavior for each scenario. Write your predictions as comments, then verify by modifying Q6.1.\n",
        "\n",
        "| Scenario | temperature | max_tokens | n | Your Prediction |\n",
        "|----------|:-----------:|:----------:|:-:|----------------|\n",
        "| A | 0 | 100 | 2 | Will both outputs be identical? |\n",
        "| B | 2 | 5 | 4 | Will outputs be coherent sentences? |\n",
        "| C | 0.5 | 2000 | 1 | Will the email be cut short by stop words? |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Write your predictions here\n",
        "\n",
        "# Scenario A (temperature=0, max_tokens=100, n=2):\n",
        "# My prediction: ___\n",
        "\n",
        "# Scenario B (temperature=2, max_tokens=5, n=4):\n",
        "# My prediction: ___\n",
        "\n",
        "# Scenario C (temperature=0.5, max_tokens=2000, n=1, stop=(\"Sincerely\",\"Best regards\")):\n",
        "# My prediction: ___\n",
        "\n",
        "print(\"Predictions written! Now go modify Q6.1 to verify each one. ‚úÖ\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## üìù Self-Assessment Checklist\n",
        "\n",
        "| # | Checkpoint | Key Concept | Done? |\n",
        "|---|-----------|------------|-------|\n",
        "| 1 | Installed `openai` and created the client | `from openai import OpenAI`, `OpenAI(api_key=...)` | ‚òê |\n",
        "| 2 | First API call with `ask_gpt()` | `system` + `user` messages, `response.choices[0].message.content` | ‚òê |\n",
        "| 3 | Understand system prompts | Realm, task, context, style constraints | ‚òê |\n",
        "| 4 | Multi-turn chatbot with history | Append user + assistant messages, pass full history | ‚òê |\n",
        "| 5 | Hyperparameters experiment | `temperature`, `max_tokens`, `top_p`, `n`, `stop` | ‚òê |\n",
        "| 6 | Predicted hyperparameter behavior | Low temp = deterministic, high temp = random, stop = early cut | ‚òê |"
      ],
      "metadata": {}
    }
  ]
}